{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Camposer</p> <p>Kotlin Multiplatform Camera Library</p> <p>         Camposer is built with Jetpack Compose and gives you a modern camera stack for Android and iOS:         photo capture, video recording, flash/torch controls, zoom, focus, stabilization, and analyzers.     </p>"},{"location":"#platform-support","title":"Platform Support","text":"<p>Camposer is a Kotlin Multiplatform library supporting:</p> Platform Status Android \u2705 Supported iOS \u2705 Supported"},{"location":"#features","title":"Features","text":"<ul> <li>Camera Session</li> <li>Camera Selector</li> <li>Capture Mode</li> <li>Camera Controller<ul> <li>Take Picture</li> <li>Record Video</li> </ul> </li> <li>Camera Format (Resolution, FPS, Video stabilization)</li> <li>Mirror Mode</li> <li>Orientation Strategy</li> <li>Image Capture Strategy</li> <li>Focus on Tap</li> <li>Zoom</li> <li>Flash Mode &amp; Torch</li> <li>Exposure compensation</li> <li>Code Analyzer</li> <li>Image Analyzer</li> <li>Implementation mode (only Android)</li> </ul>"},{"location":"camera-capture-mode/","title":"Capture Mode","text":"<p>The <code>captureMode</code> parameter defines the current operating mode of the camera, either photo capture or video recording.</p> <p>Camposer provides two available modes:</p> <ul> <li>CaptureMode.Image (default) - Enables still image capture mode</li> <li>CaptureMode.Video - Enables video recording mode.</li> </ul> <pre><code>var captureMode by remember { mutableStateOf(CaptureMode.Image) }\nval cameraSession = rememberCameraSession()\n\nCameraPreview(\n    cameraSession = cameraSession,\n    captureMode = captureMode,\n) {\n    Button(\n        onClick = {\n            captureMode = when (captureMode) {\n                CaptureMode.Image -&gt; CaptureMode.Video\n                CaptureMode.Video -&gt; CaptureMode.Image\n            }\n        }\n    ) {\n        Text(\n            \"Switch to ${if (captureMode == CaptureMode.Image) \"Video\" else \"Image\"} Mode\"\n        )\n    }\n}\n</code></pre> <p>To capture photos or record videos, see the following sections for detailed usage examples and best practices.</p>"},{"location":"camera-capture-mode/#notes","title":"Notes","text":"<ul> <li>When set to <code>CaptureMode.Image</code>, the controller enables still photo functionality.</li> <li>When set to <code>CaptureMode.Video</code>, recording related APIs become available.</li> </ul>"},{"location":"camera-format/","title":"Camera Format","text":""},{"location":"camera-format/#introduction","title":"Introduction","text":"<p>Camera Format defines the output configuration for resolution, aspect ratio, frame rate (FPS), and video stabilization.</p> <p>In most cases, the predefined resolution presets are sufficient:</p> <ul> <li>CamFormat.UltraHigh: 4K resolution (3840 \u00d7 2160)</li> <li>CamFormat.High: Full HD / 2K resolution (1920 \u00d7 1080)</li> <li>CamFormat.Medium: HD resolution (1280 \u00d7 720)</li> <li>CamFormat.Low: SD resolution (720 \u00d7 480)</li> </ul> <p>The camera format automatically selects the best available match based on the provided values.</p>"},{"location":"camera-format/#usage-example","title":"Usage example","text":"<pre><code>// ...\nval camFormat = CamFormat.High\n\nCameraPreview(\n    cameraSession = cameraSession,\n    camFormat = camFormat,\n)\n</code></pre>"},{"location":"camera-format/#custom-camera-format","title":"Custom Camera Format","text":"<p>For advanced configurations, such as higher frame rates or specific video stabilization modes, you can define a custom camera format by passing configuration options to the constructor. </p> <p>The order of these configurations matters, as Camposer prioritizes them sequentially.</p> <p>Warning</p> <p>Some configurations are not yet supported on Android. For instance, <code>VideoStabilizationConfig</code> is currently limited by the CameraX controller and not possible to be set. </p> <p>Additionally, <code>FrameRateConfig</code> may not work for values other than 24, 30, or 60 FPS on Android.</p> <pre><code>// ...\nval camFormat = remember {\n    CamFormat(\n        ResolutionConfig(3840, 2160),\n        AspectRatio(16F / 9F),\n        FrameRateConfig(60),\n        VideoStabilizationConfig(VideoStabilizationMode.Standard)\n    )\n}\n\nCameraPreview(\n    cameraSession = cameraSession,\n    camFormat = camFormat,\n)\n</code></pre>"},{"location":"camera-format/#configuration-priority","title":"Configuration Priority","text":"<p>The camera format uses a scoring and fallback mechanism. Based on the example above, it attempts to match configurations in the following order:</p> <ol> <li>ResolutionConfig + AspectRatio + FrameRateConfig + VideoStabilizationConfig</li> <li>ResolutionConfig + AspectRatio + FrameRateConfig</li> <li>ResolutionConfig + AspectRatio + VideoStabilizationConfig</li> <li>ResolutionConfig + AspectRatio</li> <li>ResolutionConfig + FrameRateConfig</li> <li>ResolutionConfig + VideoStabilizationConfig</li> <li>ResolutionConfig</li> </ol> <p>Info</p> <p>Support for some configurations on Android depends on CameraX. Having these features available in the device\u2019s native camera does not necessarily mean they are supported by CameraX.</p>"},{"location":"camera-selector/","title":"Camera Selector","text":""},{"location":"camera-selector/#introduction","title":"Introduction","text":"<p>The Camera Selector module provides a simple interface to switch between available cameras. Two predefined selectors are available:</p> <p><code>CamSelector.Back</code> \u2013 the device\u2019s default rear camera.</p> <p><code>CamSelector.Front</code> \u2013 the device\u2019s default front camera.</p> <p>The selected camera can be managed as a Compose state, allowing seamless integration into composable functions.</p>"},{"location":"camera-selector/#usage-example","title":"Usage Example","text":"<p>The following example demonstrates how to display a camera preview and switch between cameras: <pre><code>@Composable\nfun Camera() {\n  var camSelector by remember { mutableStateOf(CamSelector.Back) } // Or CamSelector.Front\n  CameraPreview(camSelector = camSelector) {\n    Button(onClick = {\n      camSelector = camSelector.inverse // Switch Camera\n    }) { \n       Text(\"Switch\") \n    }\n  }\n}\n</code></pre></p>"},{"location":"camera-selector/#custom-camera-selector","title":"Custom Camera Selector","text":"<p>You can customize the camera selection by using <code>CamSelector</code>. It allows you to specify the camera position and one or more lens types such as Wide, UltraWide, or Telephoto. </p> <p>These options can be combined to define exactly which cameras are eligible for use.</p>"},{"location":"camera-selector/#usage-example_1","title":"Usage example","text":"<pre><code>@Composable\nfun CameraPreviewScreen() {\n  val controller = remember { CameraController() }\n  val cameraSession = rememberCameraSession(controller)\n  val camSelector = remember {\n    CamSelector(\n        camPosition = CamPosition.Back,\n        camLensTypes = listOf(\n          CamLensType.UltraWide,\n          CamLensType.Wide,\n          CamLensType.Telephoto,\n        )\n    )\n  }\n\n  CameraPreview(\n    cameraSession = cameraSession,\n    camSelector = camSelector,\n  )\n}\n</code></pre> <p>If the specified camera selector is not supported, the system will fall back to the closest available match.</p> <p>Note: multi-camera lens support on Android depends on CameraX. Having multiple lenses on a device does not necessarily mean they are supported.</p>"},{"location":"camera-selector/#custom-own-camera-selector-advanced","title":"Custom own Camera Selector (Advanced)","text":"<p>For advanced use cases, you can also retrieve the list of available camera devices and explicitly select the desired one.</p>"},{"location":"camera-selector/#usage-example_2","title":"Usage example","text":"<pre><code>@Composable\nfun CameraPreviewScreen() {\n  val controller = remember { CameraController() }\n  val cameraSession = rememberCameraSession(controller)\n  val cameraDevicesState = rememberCameraDeviceState()\n  var camSelector by remember { mutableStateOf(CamSelector.Back) }\n\n  LaunchedEffect(cameraDevicesState) {\n    if (cameraDevicesState is CameraDeviceState.Devices) {\n      val cameraDevices = cameraDevicesState.cameraDevices\n      val selectedDevice = cameraDevices.find { /* your logic */ }\n      if (selectedDevice != null) {\n        camSelector = CamSelector(selectedDevice)\n      }\n    }\n  }\n\n  CameraPreview(\n    cameraSession = cameraSession,\n    camSelector = camSelector,\n  )\n}\n</code></pre>"},{"location":"camera-selector/#external-camera-experimental","title":"External Camera (Experimental)","text":"<p>Camposer also supports external cameras, such as Continuity Camera Devices on iOS, UVC cameras (mostly supported on iPad), or cameras supported by CameraX on Android.</p>"},{"location":"camera-selector/#camera-switch-callback-android-only","title":"Camera Switch Callback (Android only)","text":"<p>To handle events triggered by camera changes, the <code>onPreviewStreamChanged</code> callback is available:</p> <p><code>onPreviewStreamChanged</code>: Invoked whenever the camera preview stream changes</p> <p><code>onSwitchCameraContent: @Composable (ImageBitmap) -&gt; Unit</code>: Composable invoked whenever the camera preview stream changes, providing the current frame as a Bitmap.</p> <p>This can be used for tasks such as processing the camera feed or updating UI elements in response to camera switching.</p>"},{"location":"camera-session/","title":"Camera Session","text":""},{"location":"camera-session/#introduction","title":"Introduction","text":"<p><code>CameraSession</code> is the central component that manages the camera lifecycle and provides access to the camera\u2019s state, information, and controller. It serves as the main bridge between the UI and the camera hardware.</p>"},{"location":"camera-session/#creating-a-camera-session","title":"Creating a Camera Session","text":"<p>Use <code>rememberCameraSession</code> to create and remember a camera session across recompositions:</p> <pre><code>@Composable\nfun MyCameraScreen() {\n    val cameraController = remember { CameraController() }\n    val cameraSession = rememberCameraSession(cameraController)\n\n    CameraPreview(cameraSession = cameraSession)\n}\n</code></pre> <p>Alternatively, you can create a session without explicitly passing a controller:</p> <pre><code>val cameraSession = rememberCameraSession()\n</code></pre> <p>In this case, a controller is created internally and can be accessed via <code>cameraSession.controller</code>.</p>"},{"location":"camera-session/#components","title":"Components","text":"<p><code>CameraSession</code> provides access to three main components:</p>"},{"location":"camera-session/#1-state-camerasessionstate","title":"1. State (<code>cameraSession.state</code>)","text":"<p>The <code>state</code> holds all mutable camera configurations such as:</p> <ul> <li><code>captureMode</code>: Image or Video mode</li> <li><code>camSelector</code>: Front or Back camera</li> <li><code>flashMode</code>: Flash settings (Off, On, Auto)</li> <li><code>zoomRatio</code>: Current zoom level</li> <li><code>exposureCompensation</code>: Exposure adjustment</li> <li><code>isTorchEnabled</code>: Torch on/off state</li> <li><code>mirrorMode</code>: Mirror mode configuration</li> <li>And many more camera settings</li> </ul> <p>Example: <pre><code>val cameraSession = rememberCameraSession()\nval flashMode by cameraSession.state.flashMode.collectAsStateWithLifecycle()\nval zoomRatio by cameraSession.state.zoomRatio.collectAsStateWithLifecycle()\n</code></pre></p>"},{"location":"camera-session/#2-info-camerasessioninfo","title":"2. Info (<code>cameraSession.info</code>)","text":"<p>The <code>info</code> provides read-only hardware capabilities of the current camera and limits through <code>CameraInfoState</code>:</p> <ul> <li><code>minZoom</code> / <code>maxZoom</code>: Zoom range</li> <li><code>minExposure</code> / <code>maxExposure</code>: Exposure range</li> <li><code>isFlashSupported</code>: Flash availability</li> <li><code>isTorchSupported</code>: Torch availability</li> <li><code>isFocusSupported</code>: Focus capability</li> <li><code>minFPS</code> / <code>maxFPS</code>: Frame rate limits</li> <li><code>photoFormats</code> / <code>videoFormats</code>: Supported capture formats</li> </ul> <p>Example: <pre><code>import com.ujizin.camposer.lifecycle.compose.collectStateWithLifecycle\n\nval cameraSession = rememberCameraSession()\nval cameraInfoState by cameraSession.info.collectStateWithLifecycle() // or val cameraInfoState by cameraSession.info.state.collectAsStateWithLifecycle()\nval isFlashSupported = cameraInfoState.isFlashSupported\nval maxZoom = cameraInfoState.maxZoom\n\nif (isFlashSupported) {\n    // Show flash button\n}\n</code></pre></p>"},{"location":"camera-session/#3-controller-camerasessioncontroller","title":"3. Controller (<code>cameraSession.controller</code>)","text":"<p>The <code>controller</code> provides methods to perform camera operations:</p> <ul> <li><code>takePicture()</code>: Capture a photo</li> <li><code>startRecording()</code> / <code>stopRecording()</code>: Record video</li> <li><code>setZoomRatio()</code>: Adjust zoom</li> <li><code>setFlashMode()</code>: Change flash mode</li> <li><code>setExposureCompensation()</code>: Adjust exposure</li> <li>And more camera actions</li> </ul> <p>Example: <pre><code>val controller = remember { CameraController() }\nval cameraSession = rememberCameraSession(controller)\n\nButton(onClick = {\n    controller.takePicture { result -&gt;\n        when(result) {\n            is CaptureResult.Success -&gt; { /* Handle success */ }\n            is CaptureResult.Error -&gt; { /* Handle error */ }\n        }\n    }\n}) {\n    Text(\"Take Picture\")\n}\n</code></pre></p>"},{"location":"camera-session/#session-status-properties","title":"Session Status Properties","text":""},{"location":"camera-session/#isstreaming","title":"isStreaming","text":"<p>Indicates whether the camera is currently streaming (preview is active).</p> <pre><code>val cameraSession = rememberCameraSession()\nval isStreaming by rememberUpdatedState(cameraSession.isStreaming)\n\nif (isStreaming) {\n    // Camera preview is active\n}\n</code></pre>"},{"location":"camera-session/#isinitialized","title":"isInitialized","text":"<p>Indicates whether the camera session has been fully initialized.</p> <pre><code>val cameraSession = rememberCameraSession()\nval isInitialized by rememberUpdatedState(cameraSession.isInitialized)\n\nif (isInitialized) {\n    // Camera is ready to use\n}\n</code></pre>"},{"location":"exposure-compensation/","title":"Exposure Compensation","text":"<p>The exposureCompensation parameter allows you to manually adjust the camera\u2019s exposure level, controlling how bright or dark the preview and captured images appear.</p> <p>This value is represented as a Float, and its valid range depends on the active camera.</p>"},{"location":"exposure-compensation/#checking-supported-range","title":"Checking Supported Range","text":"<p>You can check the minimum and maximum supported exposure values for the current camera using:</p> <pre><code>import com.ujizin.camposer.lifecycle.compose.collectStateWithLifecycle\n\nval cameraInfoState by cameraSession.info.collectStateWithLifecycle()\nval minExposure = cameraInfoState.minExposure\nval maxExposure = cameraInfoState.maxExposure\n</code></pre> <p>To set the desired exposure compensation, use the CameraController.</p> <pre><code>cameraController.setExposureCompensation(1F)\n</code></pre>"},{"location":"exposure-compensation/#usage-example","title":"Usage Example","text":"<pre><code>import androidx.lifecycle.compose.collectAsStateWithLifecycle\nimport com.ujizin.camposer.lifecycle.compose.collectStateWithLifecycle\n\nval controller = remember { CameraController() }\nval cameraSession = rememberCameraSession(controller)\nval cameraInfoState by cameraSession.info.collectStateWithLifecycle()\nval minExposure = cameraInfoState.minExposure\nval maxExposure = cameraInfoState.maxExposure\nval exposureCompensation by cameraSession.state.exposureCompensation.collectAsStateWithLifecycle()\n\nCameraPreview(\n    cameraSession = cameraSession,\n) {\n    Row {\n        Button(onClick = {\n            val exposure = (exposureCompensation - 1F).coerceAtLeast(minExposure)\n            controller.setExposureCompensation(exposure)\n        }) {\n            Text(\"-\")\n        }\n\n        Text(\"Exposure: $exposureCompensation\")\n\n        Button(onClick = {\n            val exposure = (exposureCompensation + 1f).coerceAtMost(maxExposure)\n            controller.setExposureCompensation(exposure)\n        }) {\n            Text(\"+\")\n        }\n    }\n}\n</code></pre>"},{"location":"flash-mode/","title":"Flash Mode &amp; Torch","text":""},{"location":"flash-mode/#introduction","title":"Introduction","text":"<p>To configure flash mode, you need to use the <code>CameraController</code>. This ensures stability and prevents bugs or crashes when camera configuration changes.</p> <p>It\u2019s also important to note that flash needs to be supported by the camera. To check this, you can access:</p> <pre><code>val cameraInfoState by cameraSession.info.collectStateWithLifecycle()\n\n// Check if flash is supported\nval isFlashSupported = cameraInfoState.isFlashSupported\n\n// Check if torch is supported\nval isTorchSupported = cameraInfoState.isTorchSupported\n</code></pre>"},{"location":"flash-mode/#usage-example","title":"Usage Example","text":"<p>The following example demonstrates initializing flash mode and toggling it via a button. By default, the flash starts in the Off state:</p> <pre><code>val cameraController = remember { CameraController() }\nval cameraSession = rememberCameraSession(cameraController)\nval flashMode by cameraSession.state.flashMode.collectAsStateWithLifecycle()\nval isTorchEnabled by cameraSession.state.isTorchEnabled.collectAsStateWithLifecycle()\n\nCameraPreview(\n    cameraSession = cameraSession\n) {\n    Button(\n        onClick = { cameraController.setFlashMode(flashMode.inverse) } // Options: .Off, .On, .Auto (default: Off)\n    ) {\n        Text(\"Flash $flashMode\")\n    }\n\n    Button(\n        onClick = { cameraController.setTorchEnabled(!isTorchEnabled) } // Options: true, false\n    ) {\n        Text(\"Torch $isTorchEnabled\")\n    }\n}\n</code></pre>"},{"location":"focus-on-tap/","title":"Focus on Tap","text":""},{"location":"focus-on-tap/#introduction","title":"Introduction","text":"<p>Focus on Tap is enabled by default in Camposer on supported devices. Users can tap the camera preview to focus at a specific point.</p>"},{"location":"focus-on-tap/#check-focus-on-tap-support","title":"Check Focus-on-Tap Support","text":"<p>To determine whether the device supports focus on tap functionality, use the <code>isFocusSupported</code> property from cameraSession:</p> <pre><code>import com.ujizin.camposer.lifecycle.compose.collectStateWithLifecycle\n\nval cameraInfoState by cameraSession.info.collectStateWithLifecycle()\nval isFocusSupported = cameraInfoState.isFocusSupported\n</code></pre>"},{"location":"focus-on-tap/#disable-focus-on-tap","title":"Disable Focus on Tap","text":"<pre><code>val isFocusOnTapEnabled by remember { mutableStateOf(false) }\n\nCameraPreview(\n    // ...\n    isFocusOnTapEnabled = isFocusOnTapEnabled\n)\n</code></pre>"},{"location":"focus-on-tap/#custom-focus-content","title":"Custom Focus Content","text":"<p>You can provide a custom composable for the focus indicator using focusTapContent: <pre><code>CameraPreview(\n    // ...\n    focusTapContent = { \n        AwesomeFocusTapContent() \n    }\n)\n</code></pre></p>"},{"location":"focus-on-tap/#custom-focus-ui-duration","title":"Custom Focus UI Duration","text":"<p>The <code>CameraPreview.onFocus</code> parameter provides complete control over the focus indicator behavior. It is a suspendable callback that receives an onComplete function, which should be called when the focus layout should be removed.</p> <p>Default Behavior: the focus layout disappears after 1 second.</p> <pre><code>CameraPreview(\n    // ...\n    onFocus = { onComplete -&gt;\n        delay(10_000L) // Keep focus UI visible for 10 seconds\n        onComplete()\n    }\n)\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#permissions","title":"Permissions","text":"<p>Before using Camposer, you must request Camera permission, and Audio/Microphone permission if recording video.</p> <p>Camposer does not provide an API for requesting permissions. You can handle this manually or use a third-party library such as moko-permissions.</p> <p>Ensure permissions are granted before creating or displaying the <code>CameraPreview</code> composable to avoid crashes or undefined behavior.</p>"},{"location":"getting-started/#adding-the-dependency","title":"Adding the Dependency","text":"<p>To include Camposer in your project, add the dependency to the <code>commonMain.dependencies</code> block in your <code>build.gradle.kts</code> file:</p> <pre><code>implementation(\"io.github.ujizin:camposer:&lt;version&gt;\")\n</code></pre> <p>You can find the latest version at the top-right corner of this documentation or on the Camposer GitHub page.</p>"},{"location":"getting-started/#using-camerapreview-compose","title":"Using CameraPreview Compose","text":"<p>Camposer provides the CameraPreview composable, which displays a live camera feed directly within your Compose UI. It serves as the main entry point for integrating camera functionality into your app.</p> <pre><code>@Composable\nfun MyScreen() {\n    val cameraController = remember { CameraController() }\n    val cameraSession = rememberCameraSession(cameraController)\n    var camSelector by rememberCamSelector(CamSelector.Back)\n    CameraPreview(\n        cameraSession = cameraSession,\n        camSelector = camSelector,\n    ) {\n        // Camera Preview UI\n    }\n}\n</code></pre>"},{"location":"image-capture-strategy/","title":"Image Capture Strategy","text":"<p>The imageCaptureStrategy parameter defines how the camera optimizes the photo capture process, balancing between speed and image quality.</p>"},{"location":"image-capture-strategy/#available-strategies","title":"Available Strategies","text":"Strategy Android iOS <code>ImageCaptureStrategy.MinLatency</code> <code>ImageCapture.CAPTURE_MODE_ZERO_SHUTTER_LAG</code> (Fallback to Balanced if not supported) <code>AVCapturePhotoQualityPrioritizationSpeed</code> <code>ImageCaptureStrategy.MaxQuality</code> <code>ImageCapture.CAPTURE_MODE_MAXIMIZE_QUALITY</code> <code>AVCapturePhotoQualityPrioritizationQuality</code> (High Resolution enabled) <code>ImageCaptureStrategy.Balanced</code> <code>ImageCapture.CAPTURE_MODE_MINIMIZE_LATENCY</code> <code>AVCapturePhotoQualityPrioritizationBalanced</code>"},{"location":"image-capture-strategy/#strategy-descriptions","title":"Strategy Descriptions","text":"<ul> <li> <p>MinLatency: Prioritizes speed, minimizing delay between shutter press and capture. Best for burst or quick captures.   On Android devices without Zero Shutter Lag (ZSL) support, this automatically falls back to Balanced.</p> </li> <li> <p>MaxQuality: Prioritizes maximum image quality, applying extra processing and (on iOS) enabling high-resolution capture.   May increase capture latency slightly.</p> </li> <li> <p>Balanced: Provides a middle ground between latency and quality.   Recommended as the default option for consistent results across devices.</p> </li> </ul>"},{"location":"image-capture-strategy/#usage-example","title":"Usage example","text":"<pre><code>CameraPreview(\n    // ...\n    imageCaptureStrategy = ImageCaptureStrategy.Balanced // or MinLatency, MaxQuality\n)\n</code></pre>"},{"location":"implementation-mode/","title":"Implementation Mode","text":""},{"location":"implementation-mode/#introduction","title":"Introduction","text":"<p>The implementationMode property affects Android only. It determines how the camera preview is rendered:</p> <p><code>ImplementationMode.Performance</code> (default) \u2013 Uses <code>SurfaceView</code>. High performance, minimal transformations (scaling/rotation) supported. Best for performance-critical apps.</p> <p><code>ImplementationMode.Compatible</code> \u2013 Uses <code>TextureView</code>. Slightly lower performance but supports transformations and visual effects. Useful for backward compatibility or when transformations are needed.</p> <p>Note: this mode is particularly helpful when you need to overlay UI elements (buttons, Compose layouts, animations) directly on top of the camera preview, as SurfaceView may render below other UI layers.</p>"},{"location":"implementation-mode/#usage-example","title":"Usage example","text":"<pre><code>var implementationMode by remember { mutableStateOf(ImplementationMode.Compatible) }\n\nCameraPreview(\n    implementationMode = implementationMode\n) {\n    Button(onClick = {\n        implementationMode = when (implementationMode) {\n            ImplementationMode.Performance -&gt; ImplementationMode.Compatible\n            ImplementationMode.Compatible -&gt; ImplementationMode.Performance\n        }\n    }) {\n        Text(\"Switch Implementation Mode\")\n    }\n}\n</code></pre>"},{"location":"mirror-mode/","title":"Mirror Mode","text":"<p>To enable mirror mode, configure it through the <code>CameraController</code>. The following options are available:</p> <ul> <li>MirrorMode.On: Always enabled</li> <li>MirrorMode.OnlyInFront: Enabled only when using the front camera</li> <li>MirrorMode.Off: Disabled</li> </ul> <p>This mode applies when capturing a photo or recording a video.</p>"},{"location":"mirror-mode/#usage-example","title":"Usage example","text":"<pre><code>val cameraController = remember { CameraController() }\nval cameraSession = rememberCameraSession(cameraController)\nval mirrorMode by cameraSession.state.mirrorMode.collectAsStateWithLifecycle()\n\nCameraPreview(\n    cameraSession = cameraSession,\n) {\n    Button(\n        onClick = { cameraController.setMirrorMode(\n            when (mirrorMode) {\n                MirrorMode.Off -&gt; MirrorMode.On\n                MirrorMode.On -&gt; MirrorMode.OnlyInFront\n                else -&gt; MirrorMode.Off\n            }\n        ) },\n    ) {\n        Text(\"Mirror mode: $mirrorMode\")\n    }\n}\n</code></pre>"},{"location":"orientation-strategy/","title":"Orientation Strategy","text":"<p>The Output Orientation strategy determines how captured media (images or videos) is rotated. </p> <p>It defines whether rotation is applied via metadata (e.g., EXIF tags) or by physically rotating the pixels, based on different sources of truth.</p> <p>Info</p> <p>On Android, images often use EXIF orientation tags. To display images or videos correctly, use libraries like Coil, Glide, or ExoPlayer that support EXIF rotation.</p>"},{"location":"orientation-strategy/#orientation-options","title":"Orientation Options","text":"<ul> <li> <p>Preview: Matches the camera preview\u2019s UI orientation. Provides a \u201cwhat you see is what you get\u201d result, regardless of device rotation.</p> <p>Warning</p> <p>Unfortunately, Preview mode is currently supported only on iOS.</p> </li> <li> <p>Device: Matches the device\u2019s physical orientation. The output reflects how the device is held, even if the UI is locked.</p> </li> </ul>"},{"location":"orientation-strategy/#usage-example","title":"Usage example","text":"<pre><code>val cameraController = remember { CameraController() }\nval cameraSession = rememberCameraSession(cameraController)\nval orientationStrategy by cameraSession.state.orientationStrategy.collectAsStateWithLifecycle()\nCameraPreview(\n    cameraSession = cameraSession,\n) {\n\n    Button(\n        onClick = { \n            cameraController.setOrientationStrategy(\n                when(orientationStrategy) {\n                    OrientationStrategy.Preview -&gt; OrientationStrategy.Device\n                    else -&gt; OrientationStrategy.Preview\n\n                }\n            )\n        },\n    ) {\n        Text(\"Orientation strategy: $orientationStrategy\")\n    }\n}\n</code></pre>"},{"location":"scale-type/","title":"Scale Type","text":""},{"location":"scale-type/#introduction","title":"Introduction","text":"<p>Camposer supports customizing how the camera preview content is scaled within its container using the scaleType property.</p>"},{"location":"scale-type/#available-options","title":"Available Options","text":"<p>The following table shows the corresponding values for each platform when using Camposer\u2019s preview scale types:</p> Type Android iOS FitStart FIT_START AVLayerVideoGravityResizeAspect FitCenter FIT_CENTER AVLayerVideoGravityResizeAspect FitEnd FIT_END AVLayerVideoGravityResizeAspect FillStart FILL_START AVLayerVideoGravityResizeAspectFill FillCenter FILL_CENTER AVLayerVideoGravityResizeAspectFill FillEnd FILL_END AVLayerVideoGravityResizeAspectFill"},{"location":"scale-type/#usage-example","title":"Usage Example","text":"<pre><code>CameraPreview(\n  scaleType = ScaleType.FitStart // default is ScaleType.FillCenter\n)\n</code></pre>"},{"location":"zoom/","title":"Zoom","text":""},{"location":"zoom/#zoom-support","title":"Zoom support","text":"<p>Zoom can be initialized and managed as state within Compose. The following example demonstrates how to set up and control zoom using <code>CameraController</code>:</p> <pre><code>val cameraSession = rememberCameraSession()\nval zoomRatio by cameraSession.state.zoomRatio.collectAsStateWithLifecycle()\nval cameraInfoState by cameraSession.info.collectStateWithLifecycle()\nval minZoom = cameraInfoState.minZoom\nval maxZoom = cameraInfoState.maxZoom\n\nCameraPreview(\n    cameraSession = cameraSession,\n    isPinchToZoomEnabled = true // Default is already true\n) {\n\n    Button(\n        onClick = { \n            val zoom = (zoomRatio + 1F).coerceIn(minZoom, maxZoom)\n            cameraSession.controller.setZoomRatio(zoom)\n        }\n    ) {\n        Text(\"Zoom ratio: $zoomRatio\")\n    }\n}\n</code></pre> <p>Note: The <code>isPinchToZoomEnabled</code> property is enabled by default. Pinch gestures automatically update the zoom ratio through the camera controller.</p>"},{"location":"zoom/#camera-zoom-properties","title":"Camera Zoom Properties","text":"<p>The <code>cameraSession</code> object exposes several properties that may be useful when implementing zoom functionality:</p> <p><code>cameraSession.info.state.value.minZoom</code> \u2013 Returns the minimum zoom level for the current CamSelector.</p> <p><code>cameraSession.info.state.value.maxZoom</code> \u2013 Returns the maximum zoom level for the current CamSelector.</p> <p><code>cameraSession.info.state.value.isZoomSupported</code> \u2013 Returns true if zoom is supported by the current CamSelector, false otherwise.</p>"},{"location":"camera-controller/camera-controller/","title":"Camera Controller","text":""},{"location":"camera-controller/camera-controller/#introduction","title":"Introduction","text":"<p>The Camera Controller provides functionality for taking pictures and recording videos, separating these actions from UI state management. By using a controller, you can manage camera operations independently of the CameraPreview composable.</p>"},{"location":"camera-controller/camera-controller/#usage-example","title":"Usage example","text":"<pre><code>val controller = remember { CameraController() }\nval cameraSession = rememberCameraSession(controller)\n\nCameraPreview(\n    cameraSession = cameraSession,\n)\n</code></pre>"},{"location":"camera-controller/camera-controller/#why-use-a-cameracontroller","title":"Why Use a CameraController?","text":"<p>In earlier versions of Camposer, actions such as taking pictures or recording videos were handled directly in <code>cameraSession</code>. This approach limited camera operations to the UI layer, making it difficult to separate logic from presentation.</p> <p>Starting from Camposer 1.0, the <code>CameraController</code> was introduced to decouple camera operations from UI logic, following clean architecture principles.</p> <p>For example, you can instantiate the controller in a ViewModel and handle all camera actions there, keeping the UI layer focused solely on presentation.</p>"},{"location":"camera-controller/camera-controller/#viewmodel-example","title":"ViewModel Example","text":"<pre><code>class MyViewModel : ViewModel() {\n\n    val cameraController = CameraController()\n\n    fun takePicture() {\n        cameraController.takePicture(\n            // Provide configuration and callbacks here\n        )\n    }\n\n    fun startRecording() {\n        cameraController.startRecording(\n            // Provide configuration and callbacks here\n        )\n    }\n\n    fun stopRecording() {\n        cameraController.stopRecording()\n    }\n}\n</code></pre>"},{"location":"camera-controller/camera-controller/#view-example","title":"View Example","text":"<pre><code>@Composable\nfun CameraScreen(viewModel: MyViewModel) {\n    // You can also store the CameraController in your UI state, \n    // allowing it to persist across recompositions while keeping it \n    // separate from the composable UI.\n    val cameraSession = rememberCameraSession(viewModel.cameraController)\n\n    CameraPreview(cameraSession = cameraSession)\n\n    Row {\n        Button(onClick = viewModel::takePicture) {\n            Text(\"Take Picture\")\n        }\n\n        Button(onClick = viewModel::startRecording) {\n            Text(\"Start Recording\")\n        }\n\n        Button(onClick = viewModel::stopRecording) {\n            Text(\"Stop Recording\")\n        }\n    }\n}\n</code></pre>"},{"location":"camera-controller/record-video/","title":"Recording video","text":"<p>The CameraController provides full functionality for recording videos, saving them to a specified file path (String).</p>"},{"location":"camera-controller/record-video/#file-path","title":"File Path","text":"<p>To record a video, you must provide a destination file path as a String:</p> <pre><code>val path = \"/path/to/save/video.mp4\"\n</code></pre>"},{"location":"camera-controller/record-video/#start-recording","title":"Start recording","text":"<p>Start video recording with startRecording. The callback provides the recording result:</p> <pre><code>cameraController.startRecording(path) { result -&gt;\n    when(result) {\n        is CaptureResult.Success -&gt; {\n            uiState.update { it.copy(filePath = result.data) }\n        }\n        is CaptureResult.Error -&gt; // ...\n    }\n}\n</code></pre> <ul> <li>result.data contains the saved video file path on success.</li> <li>CaptureResult.Error indicates a failure during recording.</li> </ul>"},{"location":"camera-controller/record-video/#stop-recording","title":"Stop Recording","text":"<p>Stop recording using:</p> <pre><code>cameraController.stopRecording()\n</code></pre> <ul> <li>Calling stopRecording finalizes the video and triggers the startRecording callback.</li> <li>To temporarily halt recording without finalizing the file, use <code>cameraController.pauseRecording</code>.</li> </ul>"},{"location":"camera-controller/record-video/#pause-recording","title":"Pause Recording","text":"<p>Pause an ongoing recording:</p> <pre><code>cameraController.pauseRecording()\n</code></pre>"},{"location":"camera-controller/record-video/#resume-recording","title":"Resume Recording","text":"<p>Resume a paused recording:</p> <pre><code>cameraController.resumeRecording()\n</code></pre> <ul> <li><code>resumeRecording</code> continues the same recording session without creating a new file.</li> </ul>"},{"location":"camera-controller/record-video/#android-specific-api","title":"Android-Specific API","text":"<p>On Android, <code>CameraController.startRecording</code> supports additional options to provide more control over file handling:</p> <ul> <li>ContentValues - for saving to MediaStore.</li> <li>File - for saving to a specific location.</li> <li>OutputFileOptions - for advanced camera APIs.</li> </ul> <p>These options allow you to implement custom expect/actual methods for platform-specific handling, ensuring flexibility across different use cases.</p>"},{"location":"camera-controller/take-picture/","title":"Taking Picture","text":"<p>The CameraController provides functionality for taking pictures.</p>"},{"location":"camera-controller/take-picture/#bytearray","title":"ByteArray","text":"<p>Use this option when you do not want to save the picture to a file, but just retrieve its byte data.</p>"},{"location":"camera-controller/take-picture/#usage-example","title":"Usage Example","text":"<pre><code>cameraController.takePicture { result -&gt; \n    when(result) {\n        is CaptureResult.Success -&gt; {\n            uiState.update { it.copy(imageBitmap = result.data.decodeToImageBitmap()) }\n        }\n        is CaptureResult.Error -&gt; // ...\n    }\n}\n</code></pre>"},{"location":"camera-controller/take-picture/#android-specific-api","title":"Android-Specific API","text":"<p>On Android, <code>CameraController.takePicture</code> supports additional options to provide more control over file handling:</p> <ul> <li>ContentValues - for saving to MediaStore.</li> <li>File - for saving to a specific location.</li> <li>OutputFileOptions - for advanced camera APIs.</li> </ul> <p>These options allow you to implement custom expect/actual methods for platform-specific handling, ensuring flexibility across different use cases.</p>"},{"location":"image-analyzer/code-analyzer/","title":"Code Analyzer (Code Scan)","text":""},{"location":"image-analyzer/code-analyzer/#code-scan","title":"Code scan","text":"<p>Camposer supports barcode and QR code scanning via an add-on library.</p>"},{"location":"image-analyzer/code-analyzer/#installation","title":"Installation","text":"<p>Add the library to your project:</p> <pre><code>implementation(\"io.github.ujizin:camposer-code-scanner:&lt;version&gt;\")\n</code></pre> <p>Info</p> <p>The latest version can be found at the top-right corner of this documentation or on the Camposer GitHub page.</p>"},{"location":"image-analyzer/code-analyzer/#supported-code-types","title":"Supported Code Types","text":"<p>The code scanner supports the following formats:</p> <ul> <li>QRCode</li> <li>Barcode39</li> <li>Barcode93</li> <li>Barcode128</li> <li>BarcodeEAN8</li> <li>BarcodeEAN13</li> <li>CodaBar</li> <li>ITF</li> <li>Aztec</li> <li>DataMatrix</li> <li>PDF417</li> <li>UPCE</li> <li>UPCA</li> </ul>"},{"location":"image-analyzer/code-analyzer/#code-result","title":"Code result","text":"<p>The result includes the detected text, the provided type, the frame rectangle, and the corner points.</p> <p>The frame rectangle is useful for 2D drawing, while the corner points are better suited for 3D rendering.</p>"},{"location":"image-analyzer/code-analyzer/#usage-example","title":"Usage example","text":"<pre><code>val cameraSession = rememberCameraSession()\nval codeImageAnalyzer = cameraSession.rememberCodeImageAnalyzer(\n    codeTypes = listOf(CodeType.QRCode),\n    onError = {},\n) { result -&gt;\n    // result.type - code type scanned\n    // result.text - result text\n}\n\nCameraPreview(\n    cameraSession = cameraSession,\n    imageAnalyzer = codeImageAnalyzer,\n)\n</code></pre>"},{"location":"image-analyzer/image-analyzer/","title":"Image Analyzer (Custom)","text":""},{"location":"image-analyzer/image-analyzer/#introduction","title":"Introduction","text":"<p>If you need to implement a custom image analyzer, for example, using TensorFlow or other ML frameworks, you can extend Camposer\u2019s built-in analyzer. </p> <p>This allows you to process camera frames directly while leveraging CameraPreview and cameraSession features.</p>"},{"location":"image-analyzer/image-analyzer/#defining-a-custom-analyzer-example","title":"Defining a Custom Analyzer (Example)","text":""},{"location":"image-analyzer/image-analyzer/#common","title":"Common","text":"<pre><code>fun interface OCRListener {\n    fun onAnalyzed(result: String)\n}\n\nexpect class OCRImageAnalyzer(\n    listener: OCRListener\n)\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#android","title":"Android","text":"<pre><code>actual class OCRImageAnalyzer(\n    private val listener: OCRListener\n): ImageAnalyzer.Analyzer {\n    override fun analyze(imageProxy: ImageProxy) {\n        // code to analyze ...\n        listener.onAnalyzed(result)\n    }\n}\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#ios","title":"iOS","text":"<pre><code>actual class OCRImageAnalyzer(\n    private val listener: OCRListener\n): NSObject(), AVCaptureVideoDataOutputSampleBufferDelegate {\n     override fun captureOutput(\n        output: AVCaptureOutput,\n        didOutputMetadataObjects: List&lt;*&gt;,\n        fromConnection: AVCaptureConnection,\n    ) {\n        // code to analyze ...\n        listener.onAnalyzed(result)\n    }\n}\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#using-remember-to-attach-the-analyzer-example","title":"Using remember to Attach the Analyzer (Example)","text":""},{"location":"image-analyzer/image-analyzer/#common_1","title":"Common","text":"<pre><code>@Composable\npublic expect fun cameraSession.rememberOCRAnalyzer(\n    ocrAnalyzer: OCRAnalyzer,\n): ImageAnalyzer\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#android_1","title":"Android","text":"<pre><code>@Composable\npublic actual fun cameraSession.rememberOCRAnalyzer(\n    ocrAnalyzer: OCRAnalyzer,\n) = remember(ocrAnalyzer) {\n    ImageAnalyzer(\n        controller = controller,\n        analyzer = OCRImageAnalyzer(ocrAnalyzer),\n    )\n}\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#ios_1","title":"iOS","text":"<pre><code>@Composable\npublic actual fun cameraSession.rememberOCRAnalyzer(\n    ocrAnalyzer: OCRAnalyzer,\n) = remember(ocrAnalyzer) {\n    val queue = dispatch_queue_create(\"OCRAnalyzer_queue\", null)\n    val analyzer = OCRImageAnalyzer(ocrAnalyzer)\n    ImageAnalyzer(\n        iosCameraSession = iosCameraSession,\n        analyzer = ImageAnalyzer.Analyzer(\n            output = AVCaptureMetadataOutput(), // Or output needed to your case\n            onOutputAttached =  { output -&gt;\n                output.setMetadataObjectsDelegate(analyzer, queue)\n            }\n        )\n    )\n}\n</code></pre>"},{"location":"image-analyzer/image-analyzer/#attaching-the-analyzer-in-compose-example","title":"Attaching the Analyzer in Compose (Example)","text":"<pre><code>val cameraSession = rememberCameraSession()\nval ocrImageAnalyzer = cameraSession.rememberOCRAnalyzer {\n    // Result here!\n}\n\nCameraPreview(\n    cameraSession = cameraSession,\n    imageAnalyzer = ocrImageAnalyzer,\n)\n</code></pre>"}]}